{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:52:21.290757Z",
     "iopub.status.busy": "2020-11-05T17:52:21.290354Z",
     "iopub.status.idle": "2020-11-05T17:52:21.529616Z",
     "shell.execute_reply": "2020-11-05T17:52:21.528185Z",
     "shell.execute_reply.started": "2020-11-05T17:52:21.290713Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "import sklearn.preprocessing\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:27.083113Z",
     "iopub.status.busy": "2020-11-05T17:44:27.082793Z",
     "iopub.status.idle": "2020-11-05T17:44:27.119857Z",
     "shell.execute_reply": "2020-11-05T17:44:27.118602Z",
     "shell.execute_reply.started": "2020-11-05T17:44:27.083075Z"
    }
   },
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:27.121975Z",
     "iopub.status.busy": "2020-11-05T17:44:27.121639Z",
     "iopub.status.idle": "2020-11-05T17:44:53.995941Z",
     "shell.execute_reply": "2020-11-05T17:44:53.994120Z",
     "shell.execute_reply.started": "2020-11-05T17:44:27.121938Z"
    }
   },
   "outputs": [],
   "source": [
    "preprocessor = partial(utils.preprocess_text, regexes=True, start_end_symbols=True)\n",
    "dataset = utils.IMDBDataset(preprocessor=preprocessor)\n",
    "df = dataset.dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.107634Z",
     "iopub.status.busy": "2020-11-05T17:44:54.107303Z",
     "iopub.status.idle": "2020-11-05T17:44:54.171321Z",
     "shell.execute_reply": "2020-11-05T17:44:54.170201Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.107576Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2257</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; sarafina was a fun movie, and some of the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4778</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; like his early masterpiece \"the elephant m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7284</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; when i was young i had seen very few movie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4845</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; hello playmates.i recently watched this fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6822</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; \"opening night\" released in tries to be an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  file_id score  sentiment  split  \\\n",
       "0    2257     7          1  train   \n",
       "1    4778     9          1  train   \n",
       "2    7284     8          1  train   \n",
       "3    4845     9          1  train   \n",
       "4    6822     7          1  train   \n",
       "\n",
       "                                                text  \n",
       "0  <s> sarafina was a fun movie, and some of the ...  \n",
       "1  <s> like his early masterpiece \"the elephant m...  \n",
       "2  <s> when i was young i had seen very few movie...  \n",
       "3  <s> hello playmates.i recently watched this fi...  \n",
       "4  <s> \"opening night\" released in tries to be an...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.174932Z",
     "iopub.status.busy": "2020-11-05T17:44:54.174630Z",
     "iopub.status.idle": "2020-11-05T17:44:54.216503Z",
     "shell.execute_reply": "2020-11-05T17:44:54.215142Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.174894Z"
    }
   },
   "outputs": [],
   "source": [
    "samples_amount = 500\n",
    "random_indexes = np.random.choice(\n",
    "    np.arange(df.shape[0]), size=samples_amount, replace=False\n",
    ")\n",
    "small_df = df.iloc[random_indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.218914Z",
     "iopub.status.busy": "2020-11-05T17:44:54.218611Z",
     "iopub.status.idle": "2020-11-05T17:44:54.258047Z",
     "shell.execute_reply": "2020-11-05T17:44:54.256760Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.218876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.259835Z",
     "iopub.status.busy": "2020-11-05T17:44:54.259484Z",
     "iopub.status.idle": "2020-11-05T17:44:54.308196Z",
     "shell.execute_reply": "2020-11-05T17:44:54.306789Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.259788Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_id</th>\n",
       "      <th>score</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>split</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33553</th>\n",
       "      <td>4989</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;s&gt; too much added with too much taken away fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9427</th>\n",
       "      <td>6186</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; released just before the production code c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>8806</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; i chose to see the this film on the day it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12447</th>\n",
       "      <td>9759</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>&lt;s&gt; i believe i received this film when i was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39489</th>\n",
       "      <td>445</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>test</td>\n",
       "      <td>&lt;s&gt; once upon a time there was a great america...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      file_id score  sentiment  split  \\\n",
       "33553    4989     7          1   test   \n",
       "9427     6186    10          1  train   \n",
       "199      8806     9          1  train   \n",
       "12447    9759    10          1  train   \n",
       "39489     445     3          0   test   \n",
       "\n",
       "                                                    text  \n",
       "33553  <s> too much added with too much taken away fr...  \n",
       "9427   <s> released just before the production code c...  \n",
       "199    <s> i chose to see the this film on the day it...  \n",
       "12447  <s> i believe i received this film when i was ...  \n",
       "39489  <s> once upon a time there was a great america...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.309809Z",
     "iopub.status.busy": "2020-11-05T17:44:54.309505Z",
     "iopub.status.idle": "2020-11-05T17:44:54.349766Z",
     "shell.execute_reply": "2020-11-05T17:44:54.348555Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.309771Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(df):\n",
    "    \"\"\"\n",
    "    Given a dataset, builds the corresponding word vocabulary\n",
    "    \"\"\"\n",
    "    doc_str = \" \".join(df[\"text\"].tolist()).replace(\"\\n\", \" \").replace(\"\\r\", \" \")\n",
    "    words = sorted(set(doc_str.split()))\n",
    "    vocabulary, inverse_vocabulary = dict(), dict()\n",
    "    for i, w in tqdm(enumerate(words)):\n",
    "        vocabulary[i] = w\n",
    "        inverse_vocabulary[w] = i\n",
    "    return vocabulary, inverse_vocabulary, words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.351605Z",
     "iopub.status.busy": "2020-11-05T17:44:54.351294Z",
     "iopub.status.idle": "2020-11-05T17:44:54.459151Z",
     "shell.execute_reply": "2020-11-05T17:44:54.457757Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.351555Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19383it [00:00, 765555.76it/s]\n"
     ]
    }
   ],
   "source": [
    "idx_to_word, word_to_idx, word_listing = build_vocabulary(small_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.461085Z",
     "iopub.status.busy": "2020-11-05T17:44:54.460774Z",
     "iopub.status.idle": "2020-11-05T17:44:54.502006Z",
     "shell.execute_reply": "2020-11-05T17:44:54.500770Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.461045Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19383"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_listing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.503937Z",
     "iopub.status.busy": "2020-11-05T17:44:54.503554Z",
     "iopub.status.idle": "2020-11-05T17:44:54.542766Z",
     "shell.execute_reply": "2020-11-05T17:44:54.541561Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.503899Z"
    }
   },
   "outputs": [],
   "source": [
    "def dict_to_csr(term_dict):\n",
    "    keys = list(term_dict.keys())\n",
    "    values = list(term_dict.values())\n",
    "    shape = list(np.repeat(np.asarray(keys).max() + 1, 2))\n",
    "    csr = scipy.sparse.csr_matrix((values, zip(*keys)), shape=shape)\n",
    "    return csr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.544459Z",
     "iopub.status.busy": "2020-11-05T17:44:54.544157Z",
     "iopub.status.idle": "2020-11-05T17:44:54.588638Z",
     "shell.execute_reply": "2020-11-05T17:44:54.586796Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.544422Z"
    }
   },
   "outputs": [],
   "source": [
    "def co_occurrence_count(df, idx_to_word, word_to_idx, window_size=4):\n",
    "    \"\"\"\n",
    "    Builds word-word co-occurrence matrix based on word counts\n",
    "    \"\"\"\n",
    "    counts = dict()\n",
    "    for doc in tqdm(df[\"text\"]):\n",
    "        doc_words = doc.split()\n",
    "        for doc_word_index, central_word in enumerate(doc_words):\n",
    "            central_word_index = word_to_idx[central_word]\n",
    "            context = (\n",
    "                doc_words[max(0, doc_word_index - window_size) : doc_word_index] + \n",
    "                doc_words[doc_word_index + 1 : min(doc_word_index + window_size + 1, len(doc_words))]\n",
    "            )\n",
    "            for context_word in context:   \n",
    "                context_word_index = word_to_idx[context_word]\n",
    "                key = (central_word_index, context_word_index)\n",
    "                counts[key] = counts.get(key, 0) + 1\n",
    "    sparse_matrix = dict_to_csr(counts)\n",
    "    del counts\n",
    "    return sparse_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T16:58:19.192279Z",
     "iopub.status.busy": "2020-11-05T16:58:19.191960Z",
     "iopub.status.idle": "2020-11-05T16:58:19.251525Z",
     "shell.execute_reply": "2020-11-05T16:58:19.250497Z",
     "shell.execute_reply.started": "2020-11-05T16:58:19.192238Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:00, 65793.00it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 9372.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'alessio', 1: 'chi', 2: 'ciao', 3: 'come', 4: 'lorenzo', 5: 'sei', 6: 'sono', 7: 'stai'}\n",
      "{'alessio': 0, 'chi': 1, 'ciao': 2, 'come': 3, 'lorenzo': 4, 'sei': 5, 'sono': 6, 'stai': 7}\n",
      "['alessio', 'chi', 'ciao', 'come', 'lorenzo', 'sei', 'sono', 'stai']\n",
      "{(2, 6): 2, (6, 2): 2, (6, 0): 1, (0, 6): 1, (0, 2): 1, (2, 0): 1, (2, 3): 1, (3, 2): 1, (3, 7): 1, (7, 3): 1, (6, 4): 1, (4, 6): 1, (4, 1): 1, (1, 4): 1, (1, 5): 1, (5, 1): 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 1, 1, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 0, 2, 0],\n",
       "       [0, 0, 1, 0, 0, 0, 0, 1],\n",
       "       [0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 2, 0, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_df = pd.DataFrame({'text': [\"ciao sono alessio ciao come stai\", \"ciao sono lorenzo chi sei\"]})\n",
    "tmp_idx_to_word, tmp_word_to_idx, tmp_word_listing = build_vocabulary(tmp_df)\n",
    "#tmp_word_listing = ['ciao', 'sono', 'alessio', 'lorenzo', 'come', 'chi', 'sei', 'stai']\n",
    "#tmp_idx_to_word = {0: 'ciao', 1: 'sono', 2: 'alessio', 3: 'lorenzo', 4: 'come', 5:'chi', 6:'sei', 7:'stai', 8:'test'}\n",
    "#tmp_word_to_idx = {'ciao':0, 'sono':1, 'alessio':2, 'lorenzo':3, 'come':4, 'chi':5, 'sei':6, 'stai':7, 'test':8}\n",
    "print(tmp_idx_to_word)\n",
    "print(tmp_word_to_idx)\n",
    "print(tmp_word_listing)\n",
    "my_toy_co_occurrence_matrix = fast_co_occurrence_count(tmp_df, tmp_idx_to_word, tmp_word_to_idx, window_size=1)\n",
    "my_toy_co_occurrence_matrix.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:54.593160Z",
     "iopub.status.busy": "2020-11-05T17:44:54.592856Z",
     "iopub.status.idle": "2020-11-05T17:44:58.240421Z",
     "shell.execute_reply": "2020-11-05T17:44:58.239045Z",
     "shell.execute_reply.started": "2020-11-05T17:44:54.593122Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:01<00:00, 447.31it/s]\n"
     ]
    }
   ],
   "source": [
    "if \"co_occurrence_matrix\" in globals():\n",
    "    del co_occurrence_matrix\n",
    "    gc.collect()\n",
    "    time.sleep(10.0)\n",
    "\n",
    "window_size = 4\n",
    "co_occurrence_matrix = co_occurrence_count(\n",
    "    small_df, idx_to_word, word_to_idx, window_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:44:58.245246Z",
     "iopub.status.busy": "2020-11-05T17:44:58.244928Z",
     "iopub.status.idle": "2020-11-05T17:44:58.288573Z",
     "shell.execute_reply": "2020-11-05T17:44:58.286926Z",
     "shell.execute_reply.started": "2020-11-05T17:44:58.245205Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19383x19383 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 506894 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "co_occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:45:06.904418Z",
     "iopub.status.busy": "2020-11-05T17:45:06.903962Z",
     "iopub.status.idle": "2020-11-05T17:45:06.953874Z",
     "shell.execute_reply": "2020-11-05T17:45:06.952427Z",
     "shell.execute_reply.started": "2020-11-05T17:45:06.904374Z"
    }
   },
   "outputs": [],
   "source": [
    "def cosine_similarity(p, q, transpose_p=False, transpose_q=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity of two d-dimensional matrices,\n",
    "    where their second dimension should match\n",
    "    \"\"\"\n",
    "    # If it is a vector, consider it as a single sample matrix\n",
    "    if len(p.shape) == 1:\n",
    "        p = p.reshape(1, -1)\n",
    "    if len(q.shape) == 1:\n",
    "        q = q.reshape(1, -1)\n",
    "\n",
    "    # Check if dimensions match\n",
    "    assert p.shape[1] == q.shape[1]\n",
    "\n",
    "    # Check for sparsity\n",
    "    if not hasattr(scipy.sparse, type(p).__name__):\n",
    "        p = scipy.sparse.csr_matrix(p)\n",
    "    if not hasattr(scipy.sparse, type(q).__name__):\n",
    "        q = scipy.sparse.csr_matrix(q)\n",
    "\n",
    "    # Compute cosine similarity\n",
    "    p_norm = np.sqrt(p.dot(p.T).diagonal())\n",
    "    q_norm = np.sqrt(q.dot(q.T).diagonal())\n",
    "    norms_prod = np.outer(p_norm, q_norm)\n",
    "    if transpose_p:\n",
    "        res = q.dot(p.T) / norms_prod\n",
    "    else:\n",
    "        res = p.dot(q.T) / norms_prod\n",
    "        \n",
    "    return scipy.sparse.csr_matrix(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:45:11.240389Z",
     "iopub.status.busy": "2020-11-05T17:45:11.239976Z",
     "iopub.status.idle": "2020-11-05T17:45:11.285929Z",
     "shell.execute_reply": "2020-11-05T17:45:11.284642Z",
     "shell.execute_reply.started": "2020-11-05T17:45:11.240345Z"
    }
   },
   "outputs": [],
   "source": [
    "def fast_cosine_similarity(p, q, transpose_p=False, transpose_q=False):\n",
    "    \"\"\"\n",
    "    Computes the cosine similarity of two d-dimensional matrices,\n",
    "    using pre-normalization\n",
    "    \"\"\"\n",
    "    # If it is a vector, consider it as a single sample matrix\n",
    "    if len(p.shape) == 1:\n",
    "        p = p.reshape(1, -1)\n",
    "    if len(q.shape) == 1:\n",
    "        q = q.reshape(1, -1)\n",
    "\n",
    "    # Check for sparsity\n",
    "    is_p_sparse = hasattr(scipy.sparse, type(p).__name__)\n",
    "    is_q_sparse = hasattr(scipy.sparse, type(q).__name__)\n",
    "    \n",
    "    # Normalize inputs\n",
    "    normalized_p = sklearn.preprocessing.normalize(p, axis=0)\n",
    "    normalized_q = sklearn.preprocessing.normalize(q, axis=0)\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    return (\n",
    "        normalized_p.T * normalized_q if transpose_p \n",
    "        else normalized_q.T * normalized_p\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:45:24.639403Z",
     "iopub.status.busy": "2020-11-05T17:45:24.638991Z",
     "iopub.status.idle": "2020-11-05T17:46:24.170100Z",
     "shell.execute_reply": "2020-11-05T17:46:24.168222Z",
     "shell.execute_reply.started": "2020-11-05T17:45:24.639358Z"
    }
   },
   "outputs": [],
   "source": [
    "similarity_matrix = cosine_similarity(\n",
    "    co_occurrence_matrix, co_occurrence_matrix, transpose_q=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:46:24.236626Z",
     "iopub.status.busy": "2020-11-05T17:46:24.236326Z",
     "iopub.status.idle": "2020-11-05T17:46:24.276434Z",
     "shell.execute_reply": "2020-11-05T17:46:24.275105Z",
     "shell.execute_reply.started": "2020-11-05T17:46:24.236589Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19383x19383 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 227364251 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:47:20.910924Z",
     "iopub.status.busy": "2020-11-05T17:47:20.910512Z",
     "iopub.status.idle": "2020-11-05T17:47:20.955369Z",
     "shell.execute_reply": "2020-11-05T17:47:20.954079Z",
     "shell.execute_reply.started": "2020-11-05T17:47:20.910881Z"
    }
   },
   "outputs": [],
   "source": [
    "def nearest_neighbors(word, similarity_matrix, word_to_idx, k=1, farthest=False):\n",
    "    index = word_to_idx[word]\n",
    "    similarities = []\n",
    "    for w, i in word_to_idx.items():\n",
    "        similarities.append((w, similarity_matrix[index, i]))\n",
    "    return sorted(similarities, key=lambda t: t[1], reverse=(not farthest))[1 : k + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:47:35.239504Z",
     "iopub.status.busy": "2020-11-05T17:47:35.239095Z",
     "iopub.status.idle": "2020-11-05T17:47:35.309886Z",
     "shell.execute_reply": "2020-11-05T17:47:35.307871Z",
     "shell.execute_reply.started": "2020-11-05T17:47:35.239460Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_ppmi(co_occurrence_matrix, to_dense=False):\n",
    "    \"\"\"\n",
    "    Converts a count-based co-occurrence matrix to a PPMI matrix\n",
    "    \"\"\"\n",
    "    # Compute sums\n",
    "    total_sum = float(co_occurrence_matrix.sum())\n",
    "    row_col_sums = np.array(\n",
    "        co_occurrence_matrix.sum(axis=1), dtype=np.float64\n",
    "    ).flatten()\n",
    "\n",
    "    # Get CSR matrix elements\n",
    "    if not hasattr(scipy.sparse, type(co_occurrence_matrix).__name__):\n",
    "        co_occurrence_matrix = scipy.sparse.csr_matrix(co_occurrence_matrix)\n",
    "    data, indices, indptr = (\n",
    "        list(enumerate(co_occurrence_matrix.data)),\n",
    "        co_occurrence_matrix.indices,\n",
    "        co_occurrence_matrix.indptr,\n",
    "    )\n",
    "\n",
    "    # Compute PPMI matrix\n",
    "    ppmi_data, ppmi_indices, ppmi_indptr = [], [], [0]\n",
    "    for row in tqdm(range(len(indptr) - 1)):\n",
    "        for col, elem in data[indptr[row] : indptr[row + 1]]:\n",
    "            pmi = np.log2(\n",
    "                (elem * total_sum) / (row_col_sums[row] * row_col_sums[indices[col]])\n",
    "            )\n",
    "            if pmi > 0:\n",
    "                ppmi_data.append(pmi)\n",
    "                ppmi_indices.append(indices[col])\n",
    "        if ppmi_indptr[-1] != len(ppmi_data):\n",
    "            ppmi_indptr.append(len(ppmi_data))\n",
    "\n",
    "    # Re-format as sparse matrix\n",
    "    res = scipy.sparse.csr_matrix(\n",
    "        (ppmi_data, ppmi_indices, ppmi_indptr), dtype=np.float64\n",
    "    )\n",
    "    res.eliminate_zeros()\n",
    "    return res if not to_dense else res.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:47:38.530506Z",
     "iopub.status.busy": "2020-11-05T17:47:38.530092Z",
     "iopub.status.idle": "2020-11-05T17:47:47.051753Z",
     "shell.execute_reply": "2020-11-05T17:47:47.050283Z",
     "shell.execute_reply.started": "2020-11-05T17:47:38.530463Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 19383/19383 [00:07<00:00, 2504.85it/s]\n"
     ]
    }
   ],
   "source": [
    "ppmi_occurrence_matrix = convert_ppmi(co_occurrence_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:47:51.846692Z",
     "iopub.status.busy": "2020-11-05T17:47:51.846290Z",
     "iopub.status.idle": "2020-11-05T17:47:51.890022Z",
     "shell.execute_reply": "2020-11-05T17:47:51.888932Z",
     "shell.execute_reply.started": "2020-11-05T17:47:51.846647Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<19383x19383 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 478480 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppmi_occurrence_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T18:03:04.346566Z",
     "iopub.status.busy": "2020-11-05T18:03:04.346013Z",
     "iopub.status.idle": "2020-11-05T18:03:51.692890Z",
     "shell.execute_reply": "2020-11-05T18:03:51.690971Z",
     "shell.execute_reply.started": "2020-11-05T18:03:04.346508Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model_type = \"glove\"\n",
    "embedding_dimension = 50\n",
    "embedding_model = utils.load_embedding_model(embedding_model_type, embedding_dimension)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T18:04:06.614013Z",
     "iopub.status.busy": "2020-11-05T18:04:06.613604Z",
     "iopub.status.idle": "2020-11-05T18:04:06.661774Z",
     "shell.execute_reply": "2020-11-05T18:04:06.660500Z",
     "shell.execute_reply.started": "2020-11-05T18:04:06.613969Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_OOV_terms(embedding_model, word_listing):\n",
    "    \"\"\"\n",
    "    Checks differences between pre-trained embedding model vocabulary\n",
    "    and dataset specific vocabulary in order to highlight out-of-vocabulary terms.\n",
    "    \"\"\"\n",
    "    oov_terms = []\n",
    "    for word in word_listing:\n",
    "        if word not in embedding_model.vocab:\n",
    "            oov_terms.append(word)\n",
    "    return oov_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T18:04:07.240126Z",
     "iopub.status.busy": "2020-11-05T18:04:07.239807Z",
     "iopub.status.idle": "2020-11-05T18:04:07.305656Z",
     "shell.execute_reply": "2020-11-05T18:04:07.304429Z",
     "shell.execute_reply.started": "2020-11-05T18:04:07.240089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total OOV terms: 9390 (0.48%)\n"
     ]
    }
   ],
   "source": [
    "oov_terms = check_OOV_terms(embedding_model, word_listing)\n",
    "print(f\"Total OOV terms: {len(oov_terms)} ({round(len(oov_terms) / len(word_listing), 2)}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:55:35.744854Z",
     "iopub.status.busy": "2020-11-05T17:55:35.744438Z",
     "iopub.status.idle": "2020-11-05T17:55:35.799878Z",
     "shell.execute_reply": "2020-11-05T17:55:35.798523Z",
     "shell.execute_reply.started": "2020-11-05T17:55:35.744810Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrix(\n",
    "    embedding_model,\n",
    "    embedding_dimension,\n",
    "    word_to_idx,\n",
    "    idx_to_word,\n",
    "    oov_terms,\n",
    "    co_occurrence_count_matrix,\n",
    "    method=\"mean\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds the embedding matrix of a specific dataset given a pre-trained Gensim word embedding model\n",
    "    \"\"\"\n",
    "\n",
    "    def random_embedding(embedding_dimension, interval=(-1, 1)):\n",
    "        return interval[0] + np.random.sample(embedding_dimension) + interval[1]\n",
    "\n",
    "    embedding_matrix = np.zeros((len(word_to_idx), embedding_dimension))\n",
    "    for word, index in word_to_idx.items():\n",
    "        # Words that are no OOV are taken from the Gensim model\n",
    "        if word not in oov_terms:\n",
    "            word_vector = embedding_model[word]\n",
    "        # OOV words computed as the mean of not OOV neighboring words in the dataset\n",
    "        elif method == \"mean\":\n",
    "            neighboring_word_indices = co_occurrence_count_matrix.indices[\n",
    "                co_occurrence_count_matrix.indptr[index]:co_occurrence_count_matrix.indptr[index + 1]\n",
    "            ]\n",
    "            neighboring_word_vectors = np.array(\n",
    "                [\n",
    "                    embedding_model[idx_to_word[k]]\n",
    "                    for k in neighboring_word_indices\n",
    "                    if idx_to_word[k] in embedding_model\n",
    "                ]\n",
    "            )\n",
    "            # Check if at least one neighboring word is in the Gensim model vocabulary\n",
    "            if len(neighboring_word_vectors) > 0:\n",
    "                word_vector = np.mean(neighboring_word_vectors, axis=0)\n",
    "            # If not, resort to random vectors\n",
    "            else:\n",
    "                word_vector = random_embedding(embedding_dimension)\n",
    "        # OOV words computed as random vectors in range [-1, 1]\n",
    "        elif method == \"random\":\n",
    "            word_vector = random_embedding(embedding_dimension)\n",
    "        embedding_matrix[index, :] = word_vector\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:56:50.295189Z",
     "iopub.status.busy": "2020-11-05T17:56:50.294779Z",
     "iopub.status.idle": "2020-11-05T17:56:58.704335Z",
     "shell.execute_reply": "2020-11-05T17:56:58.702570Z",
     "shell.execute_reply.started": "2020-11-05T17:56:50.295145Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = build_embedding_matrix(\n",
    "    embedding_model,\n",
    "    embedding_dimension,\n",
    "    word_to_idx,\n",
    "    idx_to_word,\n",
    "    oov_terms,\n",
    "    co_occurrence_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-05T17:56:58.772360Z",
     "iopub.status.busy": "2020-11-05T17:56:58.772056Z",
     "iopub.status.idle": "2020-11-05T17:56:58.822327Z",
     "shell.execute_reply": "2020-11-05T17:56:58.821084Z",
     "shell.execute_reply.started": "2020-11-05T17:56:58.772322Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19383, 50)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
