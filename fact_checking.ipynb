{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fact checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T21:50:13.426081Z",
     "iopub.status.busy": "2020-12-11T21:50:13.425631Z",
     "iopub.status.idle": "2020-12-11T21:50:13.505809Z",
     "shell.execute_reply": "2020-12-11T21:50:13.504686Z",
     "shell.execute_reply.started": "2020-12-11T21:50:13.426036Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from collections import namedtuple\n",
    "from functools import partial\n",
    "\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import utils\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:28:06.135469Z",
     "iopub.status.busy": "2020-12-11T14:28:06.135006Z",
     "iopub.status.idle": "2020-12-11T14:28:06.666641Z",
     "shell.execute_reply": "2020-12-11T14:28:06.665381Z",
     "shell.execute_reply.started": "2020-12-11T14:28:06.135422Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package tagsets to /root/nltk_data...\n",
      "[nltk_data]   Unzipping help/tagsets.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('tagsets')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:05:00.184195Z",
     "iopub.status.busy": "2020-12-11T14:05:00.183802Z",
     "iopub.status.idle": "2020-12-11T14:05:00.224995Z",
     "shell.execute_reply": "2020-12-11T14:05:00.223836Z",
     "shell.execute_reply.started": "2020-12-11T14:05:00.184150Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.rcParams['figure.figsize'] = [8, 6]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['axes.xmargin'] = .05\n",
    "plt.rcParams['axes.ymargin'] = .05\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:05:43.327388Z",
     "iopub.status.busy": "2020-12-11T14:05:43.326975Z",
     "iopub.status.idle": "2020-12-11T14:05:43.372786Z",
     "shell.execute_reply": "2020-12-11T14:05:43.371624Z",
     "shell.execute_reply.started": "2020-12-11T14:05:43.327343Z"
    }
   },
   "outputs": [],
   "source": [
    "def save_response_content(response, destination):\n",
    "    CHUNK_SIZE = 32768\n",
    "\n",
    "    with open(destination, \"wb\") as f:\n",
    "        for chunk in response.iter_content(CHUNK_SIZE):\n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "def download_data(data_path):\n",
    "    toy_data_path = os.path.join(data_path, \"fever_data.zip\")\n",
    "    toy_data_url_id = \"1wArZhF9_SHW17WKNGeLmX-QTYw9Zscl1\"\n",
    "    toy_url = \"https://docs.google.com/uc?export=download\"\n",
    "\n",
    "    if not os.path.exists(data_path):\n",
    "        os.makedirs(data_path)\n",
    "\n",
    "    if not os.path.exists(toy_data_path):\n",
    "        print(\"Downloading FEVER data splits...\")\n",
    "        with requests.Session() as current_session:\n",
    "            response = current_session.get(\n",
    "                toy_url, params={\"id\": toy_data_url_id}, stream=True\n",
    "            )\n",
    "        save_response_content(response, toy_data_path)\n",
    "        print(\"Download completed!\")\n",
    "\n",
    "        print(\"Extracting dataset...\")\n",
    "        with zipfile.ZipFile(toy_data_path) as loaded_zip:\n",
    "            loaded_zip.extractall(data_path)\n",
    "        print(\"Extraction completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:05:46.746306Z",
     "iopub.status.busy": "2020-12-11T14:05:46.745899Z",
     "iopub.status.idle": "2020-12-11T14:05:46.785126Z",
     "shell.execute_reply": "2020-12-11T14:05:46.784050Z",
     "shell.execute_reply.started": "2020-12-11T14:05:46.746260Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_folder = os.path.join(\"datasets\", \"fever\")\n",
    "download_data(dataset_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:20:44.742948Z",
     "iopub.status.busy": "2020-12-11T15:20:44.742513Z",
     "iopub.status.idle": "2020-12-11T15:20:45.608506Z",
     "shell.execute_reply": "2020-12-11T15:20:45.607308Z",
     "shell.execute_reply.started": "2020-12-11T15:20:44.742904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chris Hemsworth appeared in A Perfect Getaway.</td>\n",
       "      <td>2\\tHemsworth has also appeared in the science ...</td>\n",
       "      <td>3</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Roald Dahl is a writer.</td>\n",
       "      <td>0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...</td>\n",
       "      <td>7</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Roald Dahl is a governor.</td>\n",
       "      <td>0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...</td>\n",
       "      <td>8</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ireland has relatively low-lying mountains.</td>\n",
       "      <td>10\\tThe island 's geography comprises relative...</td>\n",
       "      <td>9</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ireland does not have relatively low-lying mou...</td>\n",
       "      <td>10\\tThe island 's geography comprises relative...</td>\n",
       "      <td>10</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0     Chris Hemsworth appeared in A Perfect Getaway.   \n",
       "1                            Roald Dahl is a writer.   \n",
       "2                          Roald Dahl is a governor.   \n",
       "3        Ireland has relatively low-lying mountains.   \n",
       "4  Ireland does not have relatively low-lying mou...   \n",
       "\n",
       "                                            evidence  id     label  split  \n",
       "0  2\\tHemsworth has also appeared in the science ...   3  SUPPORTS  train  \n",
       "1  0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...   7  SUPPORTS  train  \n",
       "2  0\\tRoald Dahl -LRB- -LSB- langpronˈroʊ.əld _ ˈ...   8   REFUTES  train  \n",
       "3  10\\tThe island 's geography comprises relative...   9  SUPPORTS  train  \n",
       "4  10\\tThe island 's geography comprises relative...  10   REFUTES  train  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfs = []\n",
    "for split in [\"train\", \"test\", \"val\"]:\n",
    "    split_file = os.path.join(dataset_folder, f\"{split}_pairs.csv\")\n",
    "    if os.path.isfile(split_file):\n",
    "        split_df = pd.read_csv(split_file, index_col=0)\n",
    "        split_df[\"split\"] = pd.Series([split] * len(split_df), index=split_df.index)\n",
    "        dfs.append(split_df)\n",
    "\n",
    "df = pd.concat(dfs)\n",
    "df.columns = map(str.lower, df.columns)\n",
    "df = df.reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:06:35.091255Z",
     "iopub.status.busy": "2020-12-11T14:06:35.090841Z",
     "iopub.status.idle": "2020-12-11T14:06:35.147270Z",
     "shell.execute_reply": "2020-12-11T14:06:35.145915Z",
     "shell.execute_reply.started": "2020-12-11T14:06:35.091210Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SUPPORTS', 'REFUTES'], dtype=object)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:09:31.366115Z",
     "iopub.status.busy": "2020-12-11T15:09:31.365668Z",
     "iopub.status.idle": "2020-12-11T15:09:31.484409Z",
     "shell.execute_reply": "2020-12-11T15:09:31.483041Z",
     "shell.execute_reply.started": "2020-12-11T15:09:31.366069Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (121740, 6)\n",
      "Validation set shape: (7165, 6)\n",
      "Test set shape: (7189, 6)\n"
     ]
    }
   ],
   "source": [
    "print(f'Training set shape: {df[df[\"split\"] == \"train\"].shape}')\n",
    "print(f'Validation set shape: {df[df[\"split\"] == \"val\"].shape}')\n",
    "print(f'Test set shape: {df[df[\"split\"] == \"test\"].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T14:57:32.763317Z",
     "iopub.status.busy": "2020-12-11T14:57:32.762875Z",
     "iopub.status.idle": "2020-12-11T14:57:32.823871Z",
     "shell.execute_reply": "2020-12-11T14:57:32.822731Z",
     "shell.execute_reply.started": "2020-12-11T14:57:32.763271Z"
    }
   },
   "outputs": [],
   "source": [
    "TAB_CHAR = \"\\t\"\n",
    "PERIOD_CHAR = \".\"\n",
    "LEFT_PARENS = \"-LRB-\"\n",
    "RIGHT_PARENS = \"-RRB-\"\n",
    "SQUARE_BRACKETS = r\"-LSB-.*-RSB-\"\n",
    "\n",
    "\n",
    "def preprocess_claim(text):\n",
    "    if text[-1] in string.punctuation:\n",
    "        text = text[:-1]\n",
    "    return text.strip().lower()\n",
    "\n",
    "\n",
    "def preprocess_evidence(text):\n",
    "    # Remove everything before the first tab character\n",
    "    text = text[text.find(TAB_CHAR) + len(TAB_CHAR) :]\n",
    "    # Replace tabs with spaces\n",
    "    text = text.replace(TAB_CHAR, \" \")\n",
    "    # Remove parenthesis\n",
    "    text = text.replace(LEFT_PARENS, \" \").replace(RIGHT_PARENS, \" \")\n",
    "    # Remove everything between square brackets\n",
    "    text = re.sub(SQUARE_BRACKETS, \"\", text)\n",
    "    # Remove everything after the last period\n",
    "    last_period = text.rfind(PERIOD_CHAR)\n",
    "    if last_period is not None:\n",
    "        text = text[:last_period]\n",
    "    # Remove punctuation\n",
    "    text = text.translate(text.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Remove extra whitespaces\n",
    "    text = \" \".join(text.split())\n",
    "    # Convert to lowercase\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:01:26.350197Z",
     "iopub.status.busy": "2020-12-11T15:01:26.349724Z",
     "iopub.status.idle": "2020-12-11T15:01:26.420244Z",
     "shell.execute_reply": "2020-12-11T15:01:26.419127Z",
     "shell.execute_reply.started": "2020-12-11T15:01:26.350152Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random evidence 89133\n",
      "1\tHe won an Academy Award for Best Actor , BAFTA Award for Best Actor in a Leading Role , and Golden Globe Award for Best Actor in a Musical or Comedy , for his portrayal of Ray Charles in the 2004 biographical film Ray .\tAcademy Award for Best Actor\tAcademy Award for Best Actor\tBAFTA Award\tBAFTA Award\tGolden Globe Award\tGolden Globe Award\tRay Charles\tRay Charles\tRay\tRay (film)\n",
      "he won an academy award for best actor bafta award for best actor in a leading role and golden globe award for best actor in a musical or comedy for his portrayal of ray charles in the 2004 biographical film ray\n"
     ]
    }
   ],
   "source": [
    "random_index = random.choice(df.index.tolist())\n",
    "random_evidence = df.loc[random_index][\"evidence\"]\n",
    "preprocessed_random_evidence = preprocess_evidence(random_evidence)\n",
    "print(f\"Random evidence {random_index}\")\n",
    "print(f\"{random_evidence}\")\n",
    "print(f\"{preprocessed_random_evidence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:20:53.398172Z",
     "iopub.status.busy": "2020-12-11T15:20:53.397739Z",
     "iopub.status.idle": "2020-12-11T15:20:56.836749Z",
     "shell.execute_reply": "2020-12-11T15:20:56.835415Z",
     "shell.execute_reply.started": "2020-12-11T15:20:53.398127Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chris hemsworth appeared in a perfect getaway</td>\n",
       "      <td>hemsworth has also appeared in the science fic...</td>\n",
       "      <td>3</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roald dahl is a writer</td>\n",
       "      <td>roald dahl 13 september 1916 23 november 1990 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roald dahl is a governor</td>\n",
       "      <td>roald dahl 13 september 1916 23 november 1990 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ireland has relatively low-lying mountains</td>\n",
       "      <td>the island s geography comprises relatively lo...</td>\n",
       "      <td>9</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ireland does not have relatively low-lying mou...</td>\n",
       "      <td>the island s geography comprises relatively lo...</td>\n",
       "      <td>10</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0      chris hemsworth appeared in a perfect getaway   \n",
       "1                             roald dahl is a writer   \n",
       "2                           roald dahl is a governor   \n",
       "3         ireland has relatively low-lying mountains   \n",
       "4  ireland does not have relatively low-lying mou...   \n",
       "\n",
       "                                            evidence  id     label  split  \n",
       "0  hemsworth has also appeared in the science fic...   3  SUPPORTS  train  \n",
       "1  roald dahl 13 september 1916 23 november 1990 ...   7  SUPPORTS  train  \n",
       "2  roald dahl 13 september 1916 23 november 1990 ...   8   REFUTES  train  \n",
       "3  the island s geography comprises relatively lo...   9  SUPPORTS  train  \n",
       "4  the island s geography comprises relatively lo...  10   REFUTES  train  "
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"claim\"] = df[\"claim\"].apply(preprocess_claim)\n",
    "df[\"evidence\"] = df[\"evidence\"].apply(preprocess_evidence)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:34:58.746388Z",
     "iopub.status.busy": "2020-12-11T15:34:58.745937Z",
     "iopub.status.idle": "2020-12-11T15:35:00.781416Z",
     "shell.execute_reply": "2020-12-11T15:35:00.780221Z",
     "shell.execute_reply.started": "2020-12-11T15:34:58.746342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "dtype: bool\n",
      "0    False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "print(df[\"claim\"].str.extract(r\"\\b(~)\\b\").any())\n",
    "print(df[\"evidence\"].str.extract(r\"\\b(~)\\b\").any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:35:10.750704Z",
     "iopub.status.busy": "2020-12-11T15:35:10.750256Z",
     "iopub.status.idle": "2020-12-11T15:35:10.804889Z",
     "shell.execute_reply": "2020-12-11T15:35:10.803501Z",
     "shell.execute_reply.started": "2020-12-11T15:35:10.750658Z"
    }
   },
   "outputs": [],
   "source": [
    "PADDING_TOKEN = \"~\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:35:29.782913Z",
     "iopub.status.busy": "2020-12-11T15:35:29.782476Z",
     "iopub.status.idle": "2020-12-11T15:35:29.837052Z",
     "shell.execute_reply": "2020-12-11T15:35:29.835906Z",
     "shell.execute_reply.started": "2020-12-11T15:35:29.782867Z"
    }
   },
   "outputs": [],
   "source": [
    "Vocabulary = namedtuple(\"Vocabulary\", [\"to_string\", \"from_string\", \"string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:45:19.866127Z",
     "iopub.status.busy": "2020-12-11T15:45:19.865779Z",
     "iopub.status.idle": "2020-12-11T15:45:19.924642Z",
     "shell.execute_reply": "2020-12-11T15:45:19.923385Z",
     "shell.execute_reply.started": "2020-12-11T15:45:19.866084Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_vocabulary(tokens, padding_token):\n",
    "    \"\"\"\n",
    "    Given a list of strings, builds the corresponding Vocabulary object\n",
    "    \"\"\"\n",
    "    assert padding_token not in tokens\n",
    "    words = sorted(set(tokens))\n",
    "    vocabulary, inverse_vocabulary = dict(), dict()\n",
    "    vocabulary[0] = str(padding_token)\n",
    "    inverse_vocabulary[str(padding_token)] = 0\n",
    "    for i, w in tqdm(enumerate(words)):\n",
    "        vocabulary[i + 1] = w\n",
    "        inverse_vocabulary[w] = i + 1\n",
    "    return Vocabulary(\n",
    "        to_string=vocabulary,\n",
    "        from_string=inverse_vocabulary,\n",
    "        string=[padding_token] + words,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:44:19.174731Z",
     "iopub.status.busy": "2020-12-11T15:44:19.174188Z",
     "iopub.status.idle": "2020-12-11T15:44:27.361859Z",
     "shell.execute_reply": "2020-12-11T15:44:27.360757Z",
     "shell.execute_reply.started": "2020-12-11T15:44:19.174685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['chris',\n",
       " 'hemsworth',\n",
       " 'appeared',\n",
       " 'in',\n",
       " 'a',\n",
       " 'perfect',\n",
       " 'getaway',\n",
       " 'roald',\n",
       " 'dahl',\n",
       " 'is']"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "claim_tokens = list(flatten(df[\"claim\"].str.split().tolist()))\n",
    "evidence_tokens = list(flatten(df[\"evidence\"].str.split().tolist()))\n",
    "tokens = claim_tokens + evidence_tokens\n",
    "tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:45:26.515930Z",
     "iopub.status.busy": "2020-12-11T15:45:26.515602Z",
     "iopub.status.idle": "2020-12-11T15:45:27.331724Z",
     "shell.execute_reply": "2020-12-11T15:45:27.330559Z",
     "shell.execute_reply.started": "2020-12-11T15:45:26.515888Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55af5d45b76946cfa42c21cf29c21b02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocabulary = build_vocabulary(tokens, PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:47:07.792667Z",
     "iopub.status.busy": "2020-12-11T15:47:07.792345Z",
     "iopub.status.idle": "2020-12-11T15:47:07.853793Z",
     "shell.execute_reply": "2020-12-11T15:47:07.852435Z",
     "shell.execute_reply.started": "2020-12-11T15:47:07.792626Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9476"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.from_string[\"chris\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T15:46:11.790663Z",
     "iopub.status.busy": "2020-12-11T15:46:11.790201Z",
     "iopub.status.idle": "2020-12-11T15:46:11.849003Z",
     "shell.execute_reply": "2020-12-11T15:46:11.847493Z",
     "shell.execute_reply.started": "2020-12-11T15:46:11.790617Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "43508"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary.string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T17:22:01.118721Z",
     "iopub.status.busy": "2020-12-11T17:22:01.118270Z",
     "iopub.status.idle": "2020-12-11T17:22:03.692223Z",
     "shell.execute_reply": "2020-12-11T17:22:03.690887Z",
     "shell.execute_reply.started": "2020-12-11T17:22:01.118675Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>claim</th>\n",
       "      <th>evidence</th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>split</th>\n",
       "      <th>indexed_claim</th>\n",
       "      <th>indexed_evidence</th>\n",
       "      <th>indexed_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chris hemsworth appeared in a perfect getaway</td>\n",
       "      <td>hemsworth has also appeared in the science fic...</td>\n",
       "      <td>3</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "      <td>[9476, 19069, 4942, 20352, 3069, 29751, 17367]</td>\n",
       "      <td>[19069, 18742, 4240, 4942, 20352, 38680, 34479...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>roald dahl is a writer</td>\n",
       "      <td>roald dahl 13 september 1916 23 november 1990 ...</td>\n",
       "      <td>7</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "      <td>[33347, 11731, 21088, 3069, 42418]</td>\n",
       "      <td>[33347, 11731, 893, 35007, 1558, 2058, 28017, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roald dahl is a governor</td>\n",
       "      <td>roald dahl 13 september 1916 23 november 1990 ...</td>\n",
       "      <td>8</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>train</td>\n",
       "      <td>[33347, 11731, 21088, 3069, 17844]</td>\n",
       "      <td>[33347, 11731, 893, 35007, 1558, 2058, 28017, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ireland has relatively low-lying mountains</td>\n",
       "      <td>the island s geography comprises relatively lo...</td>\n",
       "      <td>9</td>\n",
       "      <td>SUPPORTS</td>\n",
       "      <td>train</td>\n",
       "      <td>[21040, 18742, 32610, 24122, 26679]</td>\n",
       "      <td>[38680, 21120, 33900, 17284, 10467, 32610, 241...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ireland does not have relatively low-lying mou...</td>\n",
       "      <td>the island s geography comprises relatively lo...</td>\n",
       "      <td>10</td>\n",
       "      <td>REFUTES</td>\n",
       "      <td>train</td>\n",
       "      <td>[21040, 13184, 27962, 18802, 32610, 24122, 26679]</td>\n",
       "      <td>[38680, 21120, 33900, 17284, 10467, 32610, 241...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               claim  \\\n",
       "0      chris hemsworth appeared in a perfect getaway   \n",
       "1                             roald dahl is a writer   \n",
       "2                           roald dahl is a governor   \n",
       "3         ireland has relatively low-lying mountains   \n",
       "4  ireland does not have relatively low-lying mou...   \n",
       "\n",
       "                                            evidence  id     label  split  \\\n",
       "0  hemsworth has also appeared in the science fic...   3  SUPPORTS  train   \n",
       "1  roald dahl 13 september 1916 23 november 1990 ...   7  SUPPORTS  train   \n",
       "2  roald dahl 13 september 1916 23 november 1990 ...   8   REFUTES  train   \n",
       "3  the island s geography comprises relatively lo...   9  SUPPORTS  train   \n",
       "4  the island s geography comprises relatively lo...  10   REFUTES  train   \n",
       "\n",
       "                                       indexed_claim  \\\n",
       "0     [9476, 19069, 4942, 20352, 3069, 29751, 17367]   \n",
       "1                 [33347, 11731, 21088, 3069, 42418]   \n",
       "2                 [33347, 11731, 21088, 3069, 17844]   \n",
       "3                [21040, 18742, 32610, 24122, 26679]   \n",
       "4  [21040, 13184, 27962, 18802, 32610, 24122, 26679]   \n",
       "\n",
       "                                    indexed_evidence  indexed_label  \n",
       "0  [19069, 18742, 4240, 4942, 20352, 38680, 34479...              1  \n",
       "1  [33347, 11731, 893, 35007, 1558, 2058, 28017, ...              1  \n",
       "2  [33347, 11731, 893, 35007, 1558, 2058, 28017, ...              0  \n",
       "3  [38680, 21120, 33900, 17284, 10467, 32610, 241...              1  \n",
       "4  [38680, 21120, 33900, 17284, 10467, 32610, 241...              0  "
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_indexes(values, to_index):\n",
    "    \"\"\"\n",
    "    Given a list of keys and a dictionary indexed by those keys,\n",
    "    return the corresponding values in the dictionary\n",
    "    \"\"\"\n",
    "    return [to_index[v] for v in values]\n",
    "\n",
    "\n",
    "df[\"indexed_claim\"] = df[\"claim\"].apply(\n",
    "    lambda s: to_indexes(s.split(), vocabulary.from_string)\n",
    ")\n",
    "df[\"indexed_evidence\"] = df[\"evidence\"].apply(\n",
    "    lambda s: to_indexes(s.split(), vocabulary.from_string)\n",
    ")\n",
    "df[\"indexed_label\"] = pd.Categorical(df[\"label\"], ordered=True).codes\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T17:22:26.743315Z",
     "iopub.status.busy": "2020-12-11T17:22:26.742883Z",
     "iopub.status.idle": "2020-12-11T17:22:26.805124Z",
     "shell.execute_reply": "2020-12-11T17:22:26.803636Z",
     "shell.execute_reply.started": "2020-12-11T17:22:26.743269Z"
    }
   },
   "outputs": [],
   "source": [
    "class FeverDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Fever dataset for fact checking\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, df):\n",
    "        self.df = df.copy()\n",
    "        self.df = self.df.reset_index(drop=True)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        assert isinstance(index, int)\n",
    "        claim = self.df.loc[index, \"indexed_claim\"]\n",
    "        evidence = self.df.loc[index, \"indexed_evidence\"]\n",
    "        label = self.df.loc[index, \"indexed_label\"]\n",
    "        return claim, evidence, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T17:22:32.747768Z",
     "iopub.status.busy": "2020-12-11T17:22:32.747441Z",
     "iopub.status.idle": "2020-12-11T17:22:32.965141Z",
     "shell.execute_reply": "2020-12-11T17:22:32.963821Z",
     "shell.execute_reply.started": "2020-12-11T17:22:32.747726Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = FeverDataset(df[df[\"split\"] == \"train\"])\n",
    "val_dataset = FeverDataset(df[df[\"split\"] == \"val\"])\n",
    "test_dataset = FeverDataset(df[df[\"split\"] == \"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:30:28.963719Z",
     "iopub.status.busy": "2020-12-11T22:30:28.963236Z",
     "iopub.status.idle": "2020-12-11T22:30:29.032805Z",
     "shell.execute_reply": "2020-12-11T22:30:29.031451Z",
     "shell.execute_reply.started": "2020-12-11T22:30:28.963671Z"
    }
   },
   "outputs": [],
   "source": [
    "def pad_batch(batch, padding_index):\n",
    "    \"\"\"\n",
    "    This function expects to receive a list of tuples (i.e. a batch),\n",
    "    s.t. each tuple contains one (claim, evidence, label) triple\n",
    "    and returns the same sequences padded with the padding token\n",
    "    \"\"\"\n",
    "    (claims, evidences, labels) = zip(*batch)\n",
    "    claims_lenghts = [len(x) for x in claims]\n",
    "    evidences_lenghts = [len(y) for y in evidences]\n",
    "    padded_claims = pad_sequence(\n",
    "        [torch.tensor(t) for t in claims],\n",
    "        batch_first=True,\n",
    "        padding_value=padding_index,\n",
    "    )\n",
    "    padded_evidences = pad_sequence(\n",
    "        [torch.tensor(t) for t in evidences],\n",
    "        batch_first=True,\n",
    "        padding_value=padding_index,\n",
    "    )\n",
    "    labels_tensor = torch.tensor(labels, dtype=torch.float).reshape(len(batch), 1)\n",
    "    return (\n",
    "        padded_claims,\n",
    "        padded_evidences,\n",
    "        labels_tensor,\n",
    "        claims_lenghts,\n",
    "        evidences_lenghts,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:30:36.964473Z",
     "iopub.status.busy": "2020-12-11T22:30:36.964119Z",
     "iopub.status.idle": "2020-12-11T22:30:37.037874Z",
     "shell.execute_reply": "2020-12-11T22:30:37.036786Z",
     "shell.execute_reply.started": "2020-12-11T22:30:36.964425Z"
    }
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:30:37.041203Z",
     "iopub.status.busy": "2020-12-11T22:30:37.040877Z",
     "iopub.status.idle": "2020-12-11T22:30:37.093452Z",
     "shell.execute_reply": "2020-12-11T22:30:37.092270Z",
     "shell.execute_reply.started": "2020-12-11T22:30:37.041164Z"
    }
   },
   "outputs": [],
   "source": [
    "default_dataloader = partial(\n",
    "    DataLoader,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    collate_fn=partial(pad_batch, padding_index=vocabulary.from_string[PADDING_TOKEN]),\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:30:37.096178Z",
     "iopub.status.busy": "2020-12-11T22:30:37.095349Z",
     "iopub.status.idle": "2020-12-11T22:30:37.147789Z",
     "shell.execute_reply": "2020-12-11T22:30:37.146650Z",
     "shell.execute_reply.started": "2020-12-11T22:30:37.096138Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataloader = default_dataloader(train_dataset)\n",
    "val_dataloader = default_dataloader(val_dataset)\n",
    "test_dataloader = default_dataloader(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:30:37.149653Z",
     "iopub.status.busy": "2020-12-11T22:30:37.149328Z",
     "iopub.status.idle": "2020-12-11T22:30:37.228795Z",
     "shell.execute_reply": "2020-12-11T22:30:37.227726Z",
     "shell.execute_reply.started": "2020-12-11T22:30:37.149615Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 9476, 19069,  4942, 20352,  3069, 29751, 17367,     0,     0,     0,\n",
       "              0],\n",
       "         [33347, 11731, 21088,  3069, 42418,     0,     0,     0,     0,     0,\n",
       "              0],\n",
       "         [33347, 11731, 21088,  3069, 17844,     0,     0,     0,     0,     0,\n",
       "              0],\n",
       "         [21040, 18742, 32610, 24122, 26679,     0,     0,     0,     0,     0,\n",
       "              0],\n",
       "         [21040, 13184, 27962, 18802, 32610, 24122, 26679,     0,     0,     0,\n",
       "              0],\n",
       "         [38752, 18802,  6544, 24811, 27964, 29762,  8177, 11930, 38780,     0,\n",
       "              0],\n",
       "         [14033, 20020, 28352, 14504, 32930, 39179,  3069, 34683, 32257, 20352,\n",
       "            873],\n",
       "         [18384, 18384, 19519, 29023,  3069,  8018, 41847, 28352,  9342,     0,\n",
       "              0]]),\n",
       " tensor([[19069, 18742,  4240,  4942, 20352, 38680, 34479, 15799,  3382, 15902,\n",
       "          36906, 39628,  1911, 38680, 38952,  3599,  3069, 29751, 17367,  1911,\n",
       "          38680, 19657, 10248, 38680,  8227, 20352, 38680, 42290,  1932, 38680,\n",
       "          11876,  3382, 15902, 36165, 41935,  4520, 38680, 19905,  1932, 38680,\n",
       "          41524, 15902, 32377, 11944,  1932,  4520, 38680,  6988, 36712, 13467,\n",
       "          15902, 33821,  1937],\n",
       "         [33347, 11731,   893, 35007,  1558,  2058, 28017,  1786, 41578,  3069,\n",
       "           7789, 28006, 35475, 37211, 42418, 30418, 34578,  4520, 15871, 30143,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0],\n",
       "         [33347, 11731,   893, 35007,  1558,  2058, 28017,  1786, 41578,  3069,\n",
       "           7789, 28006, 35475, 37211, 42418, 30418, 34578,  4520, 15871, 30143,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0],\n",
       "         [38680, 21120, 33900, 17284, 10467, 32610, 24152, 26679, 37801,  3069,\n",
       "           8969, 30249, 42184, 35141, 27235, 33314, 15244, 20662,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0],\n",
       "         [38680, 21120, 33900, 17284, 10467, 32610, 24152, 26679, 37801,  3069,\n",
       "           8969, 30249, 42184, 35141, 27235, 33314, 15244, 20662,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0],\n",
       "         [19388, 26619, 10325, 37542, 33488, 39179, 11917, 18742,  6544, 38675,\n",
       "          28352, 32710, 24244, 20352, 38680, 18720, 30745, 15902, 35047,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0],\n",
       "         [ 3728, 37753,  3069, 26122, 32257, 20352, 41460, 20352,   869,  2839,\n",
       "          14033, 32930, 39179,  3069, 34683, 32257, 20352,   873,  2908, 42184,\n",
       "           3069, 16813, 41524, 28352, 10646,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
       "              0,     0,     0],\n",
       "         [24811, 41067, 41835, 34001, 39179, 18802,  6544, 22391, 20352,  3069,\n",
       "          26250,  8018, 18869, 29023, 23890,  3186,  2210, 25796, 41847, 28352,\n",
       "          38680,  1495,  9342, 42340, 33900, 15384,  4520, 34001, 39179, 18802,\n",
       "           6544,  3069, 42340, 33900, 15384, 19709, 38903, 14993, 37587, 38675,\n",
       "          38680, 19709, 30632, 41578, 27465, 39786, 28617, 16302,  8137,     0,\n",
       "              0,     0,     0]]),\n",
       " tensor([[1.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [0.],\n",
       "         [1.],\n",
       "         [1.],\n",
       "         [1.]]),\n",
       " [7, 5, 5, 5, 7, 9, 11, 9],\n",
       " [53, 20, 20, 18, 18, 19, 25, 49])"
      ]
     },
     "execution_count": 497,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T16:06:46.889961Z",
     "iopub.status.busy": "2020-12-11T16:06:46.889511Z",
     "iopub.status.idle": "2020-12-11T16:06:46.955972Z",
     "shell.execute_reply": "2020-12-11T16:06:46.954990Z",
     "shell.execute_reply.started": "2020-12-11T16:06:46.889916Z"
    }
   },
   "outputs": [],
   "source": [
    "EMBEDDING_DIMENSION = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T16:06:53.618016Z",
     "iopub.status.busy": "2020-12-11T16:06:53.617689Z",
     "iopub.status.idle": "2020-12-11T16:11:53.531147Z",
     "shell.execute_reply": "2020-12-11T16:11:53.529316Z",
     "shell.execute_reply.started": "2020-12-11T16:06:53.617974Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_model = utils.load_embedding_model(\n",
    "    \"glove\", embedding_dimension=EMBEDDING_DIMENSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T16:55:57.747282Z",
     "iopub.status.busy": "2020-12-11T16:55:57.746841Z",
     "iopub.status.idle": "2020-12-11T16:55:57.825681Z",
     "shell.execute_reply": "2020-12-11T16:55:57.824527Z",
     "shell.execute_reply.started": "2020-12-11T16:55:57.747237Z"
    }
   },
   "outputs": [],
   "source": [
    "def build_embedding_matrices(\n",
    "    df, embedding_model, embedding_dimension, vocabulary, splits, method=\"normal\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Builds the embedding matrices (one for each split) of a specific dataset,\n",
    "    given a pre-trained Gensim word embedding model\n",
    "    \"\"\"\n",
    "    assert method in (\"uniform\", \"normal\")\n",
    "\n",
    "    def uniform_embedding(interval=(-1, 1)):\n",
    "        return interval[0] + np.random.sample(embedding_dimension) + interval[1]\n",
    "\n",
    "    def normal_embedding():\n",
    "        return np.random.normal(embedding_dimension)\n",
    "\n",
    "    oov_terms = dict()\n",
    "    embedding_matrices = dict.fromkeys(\n",
    "        splits, np.zeros((len(vocabulary.string), embedding_dimension))\n",
    "    )\n",
    "    for split in splits:\n",
    "        tokens = set(\n",
    "            list(flatten(df[df[\"split\"] == split][\"claim\"].str.split().tolist()))\n",
    "            + list(flatten(df[df[\"split\"] == split][\"evidence\"].str.split().tolist()))\n",
    "        )\n",
    "        for word in tokens:\n",
    "            word_index = vocabulary.from_string[word]\n",
    "            word_vector = np.zeros((1, embedding_dimension))\n",
    "            # Words that are no OOV are taken from the Gensim model\n",
    "            if word in embedding_model.vocab:\n",
    "                word_vector = embedding_model[word]\n",
    "            # Compute OOV embedding, if not already done\n",
    "            elif word not in oov_terms:\n",
    "                # OOV words computed as random normal vectors\n",
    "                if method == \"normal\":\n",
    "                    word_vector = normal_embedding()\n",
    "                # OOV words computed as uniform vectors in range [-1, 1]\n",
    "                elif method == \"uniform\":\n",
    "                    word_vector = uniform_embedding()\n",
    "                # The word is not OOV anymore\n",
    "                oov_terms[word] = word_vector\n",
    "            else:\n",
    "                word_vector = oov_terms[word]\n",
    "            embedding_matrices[split][word_index, :] = word_vector\n",
    "    return embedding_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T16:56:03.977154Z",
     "iopub.status.busy": "2020-12-11T16:56:03.976831Z",
     "iopub.status.idle": "2020-12-11T16:56:15.409539Z",
     "shell.execute_reply": "2020-12-11T16:56:15.407703Z",
     "shell.execute_reply.started": "2020-12-11T16:56:03.977112Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrices = build_embedding_matrices(\n",
    "    df,\n",
    "    embedding_model,\n",
    "    EMBEDDING_DIMENSION,\n",
    "    vocabulary,\n",
    "    [\"train\", \"val\", \"test\"],\n",
    "    method=\"normal\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T16:56:58.738315Z",
     "iopub.status.busy": "2020-12-11T16:56:58.737971Z",
     "iopub.status.idle": "2020-12-11T16:56:58.813406Z",
     "shell.execute_reply": "2020-12-11T16:56:58.812220Z",
     "shell.execute_reply.started": "2020-12-11T16:56:58.738271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrices[\"train\"][0, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:05.735093Z",
     "iopub.status.busy": "2020-12-11T22:31:05.734753Z",
     "iopub.status.idle": "2020-12-11T22:31:05.829691Z",
     "shell.execute_reply": "2020-12-11T22:31:05.828541Z",
     "shell.execute_reply.started": "2020-12-11T22:31:05.735045Z"
    }
   },
   "outputs": [],
   "source": [
    "class FactCheckingModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_dimension,\n",
    "        lr=1e-3,\n",
    "        padding_index=0,\n",
    "        sentence_strategy=\"bov\",\n",
    "        merging_strategy=\"mean\",\n",
    "        threshold=0.5,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Build a generic fact checking model, with recurrent modules\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # Padding\n",
    "        self.padding_index = padding_index\n",
    "\n",
    "        # Get device\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        # Embedding module\n",
    "        self.embedding = None\n",
    "\n",
    "        # Strategy to perform sentence embedding\n",
    "        assert sentence_strategy in (\"bov\", \"mlp\", \"rnn_out_avg\", \"rnn_last\")\n",
    "        self.sentence_strategy = sentence_strategy\n",
    "\n",
    "        # Strategy to merge claims and evidences\n",
    "        assert merging_strategy in (\"mean\", \"sum\", \"cat\")\n",
    "        self.merging_strategy = merging_strategy\n",
    "\n",
    "        # Dense and dropout layers\n",
    "        self.classifier = nn.Linear(\n",
    "            embedding_dimension * 2\n",
    "            if merging_strategy == \"cat\"\n",
    "            else embedding_dimension,\n",
    "            1,\n",
    "        )\n",
    "\n",
    "        # Threshold to predict positive or negative class\n",
    "        self.threshold = threshold\n",
    "\n",
    "        # Criterion\n",
    "        self.criterion = nn.BCEWithLogitsLoss().to(self.device)\n",
    "\n",
    "        # Set default optimizer\n",
    "        self.lr = lr\n",
    "        self.optimizer = torch.optim.Adam(self.parameters(), lr=lr)\n",
    "\n",
    "        # Transfer model to device\n",
    "        self.to(self.device)\n",
    "\n",
    "    def inject_embeddings(self, embeddings):\n",
    "        \"\"\"\n",
    "        Inject the given embedding matrix in the Embedding module\n",
    "        and make it non-trainable\n",
    "        \"\"\"\n",
    "        self.embedding = nn.Embedding(\n",
    "            embeddings.shape[0], embeddings.shape[1], padding_idx=self.padding_index\n",
    "        )\n",
    "        self.embedding.weight = nn.Parameter(torch.FloatTensor(embeddings))\n",
    "        self.embedding.weight.requires_grad = False\n",
    "\n",
    "    def count_parameters(self):\n",
    "        \"\"\"\n",
    "        Return the total number of trainable parameters in the model\n",
    "        \"\"\"\n",
    "        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n",
    "\n",
    "    def _sentence_embedding(self, claims, evidences):\n",
    "        def _bag_of_vectors():\n",
    "            return claims.mean(dim=1), evidences.mean(dim=1)\n",
    "\n",
    "        def _rnn():\n",
    "            packed_claims = pack_padded_sequence(\n",
    "                embedded_claims, claims_lenghts, batch_first=True, enforce_sorted=False\n",
    "            )\n",
    "            packed_evidences = pack_padded_sequence(\n",
    "                embedded_evidences,\n",
    "                evidences_lenghts,\n",
    "                batch_first=True,\n",
    "                enforce_sorted=False,\n",
    "            )\n",
    "\n",
    "        if self.sentence_strategy == \"bov\":\n",
    "            return _bag_of_vectors()\n",
    "\n",
    "    def _merge_embeddings(self, claims, evidences):\n",
    "        if self.merging_strategy == \"mean\":\n",
    "            return (claims + evidences) / 2\n",
    "        elif self.merging_strategy == \"sum\":\n",
    "            return claims + evidences\n",
    "        elif self.merging_strategy == \"cat\":\n",
    "            return torch.stack([claims, evidences], dim=1)\n",
    "        return None\n",
    "\n",
    "    def forward(self, claims, evidences, claims_lenghts, evidences_lenghts):\n",
    "        \"\"\"\n",
    "        Perform a forward pass and return predictions over\n",
    "        a mini-batch of sequences of the same lenght\n",
    "        (one value for each possible tag for each input token)\n",
    "        \"\"\"\n",
    "        assert self.embedding is not None\n",
    "        embedded_claims = self.embedding(claims)\n",
    "        embedded_evidences = self.embedding(evidences)\n",
    "        sentence_claims, sentence_evidences = self._sentence_embedding(\n",
    "            embedded_claims, embedded_evidences\n",
    "        )\n",
    "        merged_inputs = self._merge_embeddings(sentence_claims, sentence_evidences)\n",
    "        predictions = self.classifier(merged_inputs)\n",
    "        return predictions\n",
    "\n",
    "    def predict(self, predictions, labels):\n",
    "        \"\"\"\n",
    "        Transform emission scores into labels indexes and return\n",
    "        flattened Python lists containing predictions and ground truths\n",
    "        \"\"\"\n",
    "        probabilities = torch.sigmoid(predictions.view(-1))\n",
    "        predicted_classes = (probabilities > self.threshold).float()\n",
    "        ground_truth = labels.view(-1).detach().cpu().tolist()\n",
    "        return (\n",
    "            predicted_classes.detach().cpu().tolist(),\n",
    "            labels.view(-1).detach().cpu().tolist()\n",
    "        )\n",
    "\n",
    "    def loss(self, predictions, labels):\n",
    "        \"\"\"\n",
    "        Compute the loss and return its value\n",
    "        \"\"\"\n",
    "        return self.criterion(predictions, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:05.832198Z",
     "iopub.status.busy": "2020-12-11T22:31:05.831874Z",
     "iopub.status.idle": "2020-12-11T22:31:05.887149Z",
     "shell.execute_reply": "2020-12-11T22:31:05.885580Z",
     "shell.execute_reply.started": "2020-12-11T22:31:05.832159Z"
    }
   },
   "outputs": [],
   "source": [
    "def categorical_accuracy(predictions, ground_truth):\n",
    "    \"\"\"\n",
    "    Returns accuracy score over the given batch of data\n",
    "    \"\"\"\n",
    "    return sklearn.metrics.accuracy_score(ground_truth, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:05.889060Z",
     "iopub.status.busy": "2020-12-11T22:31:05.888735Z",
     "iopub.status.idle": "2020-12-11T22:31:05.943461Z",
     "shell.execute_reply": "2020-12-11T22:31:05.942024Z",
     "shell.execute_reply.started": "2020-12-11T22:31:05.889022Z"
    }
   },
   "outputs": [],
   "source": [
    "def f1_score(\n",
    "    predictions, ground_truth, labels=None, average=\"macro\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns F1-macro score over an entire dataset\n",
    "    (F1 cannot be computed on batches)\n",
    "    \"\"\"\n",
    "    return sklearn.metrics.f1_score(\n",
    "        ground_truth, predictions, labels=labels, average=average,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:05.945186Z",
     "iopub.status.busy": "2020-12-11T22:31:05.944881Z",
     "iopub.status.idle": "2020-12-11T22:31:06.006537Z",
     "shell.execute_reply": "2020-12-11T22:31:06.005390Z",
     "shell.execute_reply.started": "2020-12-11T22:31:05.945148Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader, embeddings):\n",
    "    \"\"\"\n",
    "    Train the given model with the given dataloader\n",
    "    \"\"\"\n",
    "    epoch_loss, epoch_acc, epoch_f1 = 0, 0, 0\n",
    "    all_outputs, all_labels = [], []\n",
    "    model.train()\n",
    "    model.inject_embeddings(embeddings)\n",
    "    dataloader_progress = tqdm(enumerate(dataloader), desc=\"Training\", leave=True)\n",
    "    for i, batch in dataloader_progress:\n",
    "        model.optimizer.zero_grad()\n",
    "        claims, evidences, labels, claims_lenghts, evidences_lenghts = batch\n",
    "        predictions = model(claims, evidences, claims_lenghts, evidences_lenghts)\n",
    "        max_predictions, ground_truth = model.predict(predictions, labels)\n",
    "        acc = categorical_accuracy(max_predictions, ground_truth)\n",
    "        all_outputs.extend(max_predictions)\n",
    "        all_labels.extend(ground_truth)\n",
    "        loss = model.loss(predictions, labels)\n",
    "        loss.backward()\n",
    "        model.optimizer.step()\n",
    "        epoch_loss = epoch_loss + ((loss.item() - epoch_loss) / (i + 1))\n",
    "        epoch_acc = epoch_acc + ((acc.item() - epoch_acc) / (i + 1))\n",
    "        dataloader_progress.set_postfix({\"epoch_acc\": f\"{epoch_acc * 100:.2f}\"})\n",
    "\n",
    "    # Compute F1 score once a training epoch is done\n",
    "    epoch_f1 = f1_score(all_outputs, all_labels)\n",
    "    return epoch_loss, epoch_acc, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:06.008512Z",
     "iopub.status.busy": "2020-12-11T22:31:06.008149Z",
     "iopub.status.idle": "2020-12-11T22:31:06.068984Z",
     "shell.execute_reply": "2020-12-11T22:31:06.067820Z",
     "shell.execute_reply.started": "2020-12-11T22:31:06.008474Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, embeddings, f1_labels=None):\n",
    "    \"\"\"\n",
    "    Evaluate the given model with the given dataloader\n",
    "    \"\"\"\n",
    "    epoch_loss, epoch_acc, epoch_f1 = 0, 0, 0\n",
    "    all_outputs, all_labels = [], []\n",
    "    model.eval()\n",
    "    model.inject_embeddings(embeddings)\n",
    "    with torch.no_grad():\n",
    "        dataloader_progress = tqdm(enumerate(dataloader), desc=\"Evaluating\", leave=True)\n",
    "        for i, batch in dataloader_progress:\n",
    "            claims, evidences, labels, claims_lenghts, evidences_lenghts = batch\n",
    "            predictions = model(claims, evidences, claims_lenghts, evidences_lenghts)\n",
    "            max_predictions, ground_truth = model.predict(predictions, labels)\n",
    "            acc = categorical_accuracy(max_predictions, ground_truth)\n",
    "            all_outputs.extend(max_predictions)\n",
    "            all_labels.extend(ground_truth)\n",
    "            loss = model.loss(predictions, labels)\n",
    "            epoch_loss = epoch_loss + ((loss.item() - epoch_loss) / (i + 1))\n",
    "            epoch_acc = epoch_acc + ((acc.item() - epoch_acc) / (i + 1))\n",
    "            dataloader_progress.set_postfix({\"epoch_acc\": f\"{epoch_acc * 100:.2f}\"})\n",
    "\n",
    "    # Compute F1 score once a training epoch is done\n",
    "    epoch_f1 = f1_score(all_outputs, all_labels)\n",
    "    return epoch_loss, epoch_acc, epoch_f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:06.073249Z",
     "iopub.status.busy": "2020-12-11T22:31:06.072931Z",
     "iopub.status.idle": "2020-12-11T22:31:06.135521Z",
     "shell.execute_reply": "2020-12-11T22:31:06.134389Z",
     "shell.execute_reply.started": "2020-12-11T22:31:06.073211Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_eval(\n",
    "    model,\n",
    "    model_name,\n",
    "    train_dataloader,\n",
    "    val_dataloader,\n",
    "    train_embeddings,\n",
    "    val_embeddings,\n",
    "    epochs=10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform training, validation and testing on the given model,\n",
    "    for the specified number of epochs and return a dictionary\n",
    "    containing learning metrics\n",
    "    \"\"\"\n",
    "    history = {\n",
    "        \"train_loss\": [],\n",
    "        \"train_acc\": [],\n",
    "        \"train_f1\": [],\n",
    "        \"val_loss\": [],\n",
    "        \"val_acc\": [],\n",
    "        \"val_f1\": [],\n",
    "    }\n",
    "    epoch_progress = tqdm(range(epochs), desc=\"Epoch\", leave=True)\n",
    "    best_val_loss = np.inf\n",
    "    for epoch in epoch_progress:\n",
    "        # Perform training\n",
    "        train_loss, train_acc, train_f1 = train(\n",
    "            model, train_dataloader, train_embeddings,\n",
    "        )\n",
    "        history[\"train_loss\"].append(train_loss)\n",
    "        history[\"train_acc\"].append(train_acc)\n",
    "        history[\"train_f1\"].append(train_f1)\n",
    "\n",
    "        # Perform evaluation\n",
    "        val_loss, val_acc, val_f1 = evaluate(model, val_dataloader, val_embeddings)\n",
    "        history[\"val_loss\"].append(val_loss)\n",
    "        history[\"val_acc\"].append(val_acc)\n",
    "        history[\"val_f1\"].append(val_f1)\n",
    "\n",
    "        # Update progress bar\n",
    "        epoch_progress.set_postfix(\n",
    "            {\"train_f1\": f\"{train_f1 * 100:.2f}\", \"val_f1\": f\"{val_f1 * 100:.2f}\"}\n",
    "        )\n",
    "\n",
    "        # Save the best model so far\n",
    "        if val_loss < best_val_loss:\n",
    "            torch.save(model.state_dict(), f\"models/fact_checking/{model_name}.pt\")\n",
    "\n",
    "    # Print final validation stats\n",
    "    print(\n",
    "        f\"Final validation results:\",\n",
    "        f\"Loss: {history['val_loss'][-1]:.3f} |\",\n",
    "        f\"Accuracy: {history['val_acc'][-1] * 100:.2f}% |\",\n",
    "        f\"F1: {history['val_f1'][-1] * 100:.2f}%\",\n",
    "    )\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:06.138472Z",
     "iopub.status.busy": "2020-12-11T22:31:06.138091Z",
     "iopub.status.idle": "2020-12-11T22:31:06.190784Z",
     "shell.execute_reply": "2020-12-11T22:31:06.189433Z",
     "shell.execute_reply.started": "2020-12-11T22:31:06.138420Z"
    }
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "NUM_EPOCHS = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:06.192823Z",
     "iopub.status.busy": "2020-12-11T22:31:06.192512Z",
     "iopub.status.idle": "2020-12-11T22:31:06.245944Z",
     "shell.execute_reply": "2020-12-11T22:31:06.244823Z",
     "shell.execute_reply.started": "2020-12-11T22:31:06.192785Z"
    }
   },
   "outputs": [],
   "source": [
    "actual_train_eval = partial(\n",
    "    train_eval,\n",
    "    train_dataloader=train_dataloader,\n",
    "    val_dataloader=val_dataloader,\n",
    "    train_embeddings=embedding_matrices[\"train\"],\n",
    "    val_embeddings=embedding_matrices[\"val\"],\n",
    "    epochs=NUM_EPOCHS\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:06.247735Z",
     "iopub.status.busy": "2020-12-11T22:31:06.247420Z",
     "iopub.status.idle": "2020-12-11T22:31:06.304830Z",
     "shell.execute_reply": "2020-12-11T22:31:06.303279Z",
     "shell.execute_reply.started": "2020-12-11T22:31:06.247697Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 301 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "bov_mean_model = FactCheckingModel(\n",
    "    EMBEDDING_DIMENSION,\n",
    "    lr=LEARNING_RATE,\n",
    "    padding_index=vocabulary.from_string[PADDING_TOKEN],\n",
    "    sentence_strategy=\"bov\",\n",
    "    merging_strategy=\"mean\",\n",
    ")\n",
    "print(f\"The model has {bov_mean_model.count_parameters():,} trainable parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-12-11T22:31:06.306880Z",
     "iopub.status.busy": "2020-12-11T22:31:06.306567Z",
     "iopub.status.idle": "2020-12-11T22:31:33.716215Z",
     "shell.execute_reply": "2020-12-11T22:31:33.713984Z",
     "shell.execute_reply.started": "2020-12-11T22:31:06.306842Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2415b88e20da40c08c1c8950f3c66a85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Epoch'), FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf3c07fb650c4407ba43b1639373be4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value='Training'), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'),…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-507-36a5948ef098>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbov_mean_model_history\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactual_train_eval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbov_mean_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bov_mean_model\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-503-ef52449f0f41>\u001b[0m in \u001b[0;36mtrain_eval\u001b[0;34m(model, model_name, train_dataloader, val_dataloader, train_embeddings, val_embeddings, epochs)\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_progress\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# Perform training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         train_loss, train_acc, train_f1 = train(\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_embeddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         )\n",
      "\u001b[0;32m<ipython-input-501-b37231ad267c>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, dataloader, embeddings)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mepoch_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepoch_loss\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mepoch_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_acc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mepoch_acc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m             \u001b[0mbeta1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'betas'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             F.adam(params_with_grad,\n\u001b[0m\u001b[1;32m    109\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/optim/functional.py\u001b[0m in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m     92\u001b[0m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmax_exp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m             \u001b[0mdenom\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias_correction2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mstep_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mbias_correction1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "bov_mean_model_history = actual_train_eval(bov_mean_model, \"bov_mean_model\",)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments/summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
